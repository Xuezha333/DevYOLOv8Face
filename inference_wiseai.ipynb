{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b35d0791-0bb1-479f-8cc3-013852ce8697.jpg: 640x384 1 face, 108.7ms\n",
      "Speed: 1.6ms preprocess, 108.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed85e3a7-acc9-49d5-95fa-47adf44f87b2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e72fff25-b22e-4eb9-b3dd-3ad701a89d4d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7464335d-9d30-46fc-9493-f62cad6c4c06.jpg: 640x480 1 face, 111.0ms\n",
      "Speed: 2.0ms preprocess, 111.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6fafe175-4dd6-44a2-8aad-6be2f86accd2.jpg: 640x480 1 face, 5.9ms\n",
      "Speed: 1.9ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d2490ab-63c2-4863-9640-d02ee4bfcc5b.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aaede6bd-db7a-4ca4-a014-ecc08abc4692.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bf0ff114-3191-4dc9-a68d-8d5765f0c0aa.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/21063659-c586-46bd-928c-9ffd05d0c72d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f0b8a925-3552-4920-a562-6d77913184df.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fe35770-d1d1-4542-b9be-c0df22dbdf84.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1196aa77-79be-4d03-8b4a-5a69596784be.jpg: 640x416 1 face, 108.2ms\n",
      "Speed: 1.6ms preprocess, 108.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eeedf8b4-5184-4cdc-9e94-c7a8153471ac.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b2779c0a-1c11-439f-a1a9-c4a5b6c2894b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/90438969-d462-4a31-b2f6-26b5f21afe3a.jpg: 640x384 1 face, 16.1ms\n",
      "Speed: 5.6ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb1016cf-af6b-44f9-8832-e9f0e089998d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f94b020f-9a55-46aa-93ec-b5a9319cdb7d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/227c2acd-b9ef-4479-9e82-c65fb4bc832e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4856f564-df61-4711-9649-22438d137add.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2de2bc1b-dd43-4d9d-8963-a793b75fb556.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ffd68b82-520e-4197-992a-d542841463dd.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6268e735-46d4-4561-9377-c3890395ab4b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b16a476-4f86-49de-a855-66b88258f4d8.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5253820f-5b87-4110-a97d-6999c8db5957.jpg: 640x480 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02301118-baa1-4f4a-8708-2d2dc8326493.jpg: 640x384 1 face, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d7921dff-c4a8-4f2f-8b28-e46a12ae6d37.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9c42ce5b-a8ae-4ef1-bc67-222be6861763.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb7f866e-7991-462d-b952-0814b0e61289.jpg: 640x416 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0cb68101-8330-4748-b9ee-c87543ea3fce.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2832a3f6-f57b-4639-827f-ad179f4b35da.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e3ea4651-064e-4c1b-ac92-b4d9e3700006.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/08146453-b859-4f9f-b541-5d419be69b3c.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0f127a7a-ae96-447b-8645-3b5511500c62.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/65e54017-150c-439a-9cdb-b23e19cd5963.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/094c272e-d3b6-4535-b82d-c11b9f13b03f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2f1c72fb-7519-4ecb-9e3b-d4d67efe57e4.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9d54d3dd-1440-4ff1-a60d-659ee12a3d7c.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/71091bec-2e4a-4834-8475-70a6a9ad1bff.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8407e0de-0323-4442-bb15-bb2cb1bfdda4.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5cbb7d55-40f8-4967-9b59-8909abc7818e.jpg: 640x416 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5c3f292a-f526-44e6-94de-1635a85cc7a0.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fcd62e4b-93ca-4fa7-a0c8-c1c2d9b60028.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0e2e6322-962b-4c2a-9c9e-142eeac32d27.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4fcfb9d7-cb5f-44ec-a311-a583673aa93c.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/60186f9c-07fb-4426-8713-78a411158539.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed39b2c7-a636-4f7a-96e0-62bd55e835b2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6cd2d740-9501-44be-829f-dd3f8c15d050.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/72a68e4a-abe2-4c23-a729-ad36fa3e31ab.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7604e119-f192-43ae-9847-4bc795fc4a15.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ebd1fa5a-2296-42b5-9d87-0a2f0515473d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/29ad0a72-a2a4-46ff-ad80-45db8be07168.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8e8ba00c-3d8e-4ecd-8fde-8c394b3ead8d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a54d67e2-6cc4-4933-b24a-b31d506f4877.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/87773848-eda7-49a3-838a-716cb7381c14.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9507a7e6-d2cd-4a13-b4c8-a72292f4e587.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8186d58f-ec21-4284-9678-60a3ffd6f75a.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f7df26dd-bd76-4a6a-a4fc-4e1f2c5918ef.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0197273a-ffc6-4ef4-8e7a-a484449a152b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e20bc885-e123-4f88-bcdb-21037e65c931.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e914ab54-5e78-4845-a3f4-80b6189b115e.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/25c5a9ca-45c3-4b38-80e9-fbd905be1392.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc2ee022-9249-4089-a81a-651f5b0a7426.jpg: 640x384 1 face, 23.0ms\n",
      "Speed: 5.6ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4244c0de-1cae-4d8c-8cd2-ba69938d3a2b.jpg: 640x384 1 face, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f430e7e-005a-40ac-b0a8-611f6c4fb445.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/06cae16e-f18a-4963-b293-8f66510bab3d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8509d490-8a18-4e8b-956a-70073ad59163.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/208158c3-d2ec-4791-b426-893f1ffdd555.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b63ab055-4a97-40ef-9352-8affe5566626.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8ffd6bd7-1745-4c33-ae47-9e030fe4a565.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d444e19-de62-4ed3-a1c8-c168f4ca250a.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f00e4de1-5781-4488-a069-509fd7bc2306.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/94bb2cb0-1d4d-4207-a4f9-0a619ee27c51.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e0907964-0b04-4c1e-820f-a25b479f67fb.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/42e67695-ca98-4e0c-8690-ec6d56c346fd.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2b145af7-c8e1-4d3d-8a2b-b6f2b58d8059.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/57cd2625-f532-47ae-b15f-496dc4162bdf.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/83ea52cf-f8ad-4ad2-a116-5e3c3cf107f2.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/340dd0b6-8bc4-4729-954b-f09669ec6b84.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f8104655-49c6-489e-96b9-b9392eebaaeb.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b1d2a729-79bb-49a1-9a93-151b79151d3a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc9a4504-1ef9-4b82-903e-428f3db3c967.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe7e6e34-fa14-4908-b95d-3ef62945538f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/62f35e8a-4348-40d9-a13c-6720c6a620ff.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/92af2d20-5871-4fee-b73f-d5acc99f362d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3e24bd54-c64b-4110-923b-8b378a0b9c93.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0489e41f-4568-461b-888e-a40e4553191b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5670916f-7101-4972-9e94-3d6f383f6c90.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/586e44b2-330b-4794-9338-75923e18227b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b6a1d986-4a0c-4c78-bd4d-5152bdb4cd40.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/64a8bf2d-3fba-4409-8a38-0cc4bc1eb6ed.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5791a874-a020-426e-b011-2f66b083872b.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/62c47520-2ad7-4c01-b260-cc8d810c13b3.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f7db7f28-8591-44ea-8f97-4a992a67c831.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e341d476-f11a-4f45-8569-c4dc1eea25b3.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cd46ba0e-c901-472b-b44e-552c650ddaad.jpg: 640x480 1 face, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bdbc0311-448b-4ad4-8ab5-b6aa9714149e.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d63a86e6-2c2f-429e-81b7-be0f7725f698.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2db25e2c-b437-41ca-a2cd-0e4f60ec6171.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1ac488b7-51eb-4a59-ad84-cd2da0de9c50.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/127f4466-d095-405c-941b-2491d192a810.jpg: 640x416 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a9c16d79-d7bf-4edf-bd3c-744bed19e192.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/80aade55-7a13-4fb4-b63e-cc61a721c0f5.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e53fa46a-ff2d-4b1f-9729-1d589a84573f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d8dd307-5a03-4146-b6b0-720946fb799e.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2afc9b75-97fe-4010-ac17-4a807a6a3904.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5ede2524-9850-42ad-9fdf-bb4f944cda0a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b9cda16-afb9-4a31-b43b-87895ce4b948.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e444a994-d58c-41dc-94c8-b5bf0a68bb13.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/59567b40-a09b-4c39-ad1d-5c2223e12adc.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3deb33f6-9a3b-4b10-a73f-aa56dd1e72fa.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e871fc04-56b9-45ac-a13e-96a053f40b1c.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/929402a1-095f-4bd9-a4d8-bc9773beb226.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3a72c885-47b4-4bca-ace8-7807cf00fe48.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2acb7ceb-ec49-4380-b9b7-0d2fbf77f783.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed419063-a499-4992-8c76-4e13e31ffd0d.jpg: 640x480 1 face, 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dd39b876-385e-4267-b46a-f2a72f2585c0.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/292fffac-cabf-4bfc-bbde-73f08df4e9d6.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/98cfebfc-5ebd-4272-af6f-eba193e55193.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/73cfe5e3-8819-417a-81b9-4a9650fba472.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c0e04bc8-1ee9-4589-933e-e53a384868ab.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/52dc9454-ee3e-4eb2-8d55-c4e96a41d76f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/57fc0fe2-8c55-4d68-9714-f6a6b5a9c94b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fa7268ce-be04-4af0-b5b8-7ad5cc13aa24.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/301cd3c0-1fd9-47a9-aa54-d4d763e08e82.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1ff52429-ac72-411a-b7c7-13a5a7709088.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/661e32b0-9c45-4e40-bab0-10f46c960a05.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/db0d4701-ba6a-4d61-a7ba-283adb6ab22c.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1432516f-4cb7-4d42-9d8a-295165144c63.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9addd114-8a17-473b-994f-7f7c0e5fee28.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ad5b2db7-0816-4591-ba8a-046a4b1e534e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/64225b16-0bf0-4487-aeb6-371c0628b797.jpg: 640x480 1 face, 6.6ms\n",
      "Speed: 1.8ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e348d7f8-b89e-4d1c-a207-5b0234485ead.jpg: 640x384 1 face, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8c07266b-fe34-4300-8cc9-a53ca2e48145.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b9db7fb-2751-4409-9112-fe67ff5a7386.jpg: 640x480 1 face, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5e116d74-da91-4fd0-945d-c1dc74fde359.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb172f25-691f-4d65-ad2f-fdb4ae259c33.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d755d32b-7097-4e5b-b23e-3e5c3fc98c83.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6d61bd53-dee1-4927-b3ba-93d18fa15e2a.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/11f88196-6992-4512-80f6-7adb3ab73291.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/27b8a0d6-f8a2-422d-b86d-352004ae1386.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4385b08-2432-4e31-b68b-6623055a2dd4.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ca5a772a-402c-43f4-ad45-85862ec58cd5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/169080da-7143-4e23-b80b-c2d8062fd885.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/339dac7c-96a5-4669-bb95-f15980996915.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c7ad57f6-6569-4dba-9709-5e1c5acb10e7.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/58c156b2-e068-4ba3-a75d-3431f007ea44.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d778d0a6-79e5-409c-bdd0-9f209b20a465.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fb6f45f-5d46-4659-a001-b9695972b2eb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ff24ee66-ddf7-4597-a8c1-70900aec0e94.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/097c1aef-cb9c-4908-a452-ea6f67ef2f9a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e5bbe438-0c0a-4477-9ea2-d93ff9230ebb.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81ff11d8-9cca-40c3-b901-0e635ae3535e.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd8e7198-7a3d-4dc1-9edb-c2af543bf7f9.jpg: 384x640 1 face, 104.8ms\n",
      "Speed: 1.6ms preprocess, 104.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7006f08c-db51-4f85-98cf-1eeeba9de217.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e6add8f3-bbc9-4c49-aa50-4e11edf47118.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9b99bf75-92e6-4d42-b637-0e398f456ae3.jpg: 640x480 1 face, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/97d7c632-3035-41f2-919c-858fbc7be4bf.jpg: 640x480 1 face, 5.6ms\n",
      "Speed: 1.7ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6d614945-96c9-4b9a-9002-848f30078daf.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/99bf3278-f9fa-4305-b63c-14d3d03b0041.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa661d81-7b0c-491d-ab57-e2a761b6df12.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aec77992-f2c8-4db0-99ba-cc5df90e20a2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/111da176-4272-4c8c-89f7-e5c9edcedafb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/252889d4-6534-4925-b674-4d7549042c90.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/63b94c54-da68-48b7-b26f-008698cf20e7.jpg: 640x416 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1d1fb904-428e-405e-a105-99c21a9c055a.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3561b0aa-c4f9-4cf7-a0b8-d1c09cff37b9.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e7ae8f4b-2705-4434-b902-862b6a4a0afc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1dbfd7ad-8450-47fc-87d2-ffe112bb70ad.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4417f226-63b7-4a1d-bdc0-3b3a71143dd6.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ddf9088c-2719-42f8-b16b-806ef3039561.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/570fafee-fac9-4106-935e-928bb2768dc8.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4d481c8-55ee-4f58-9388-37b940b3665c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.9ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/46bf17f6-0064-4de0-9d04-75a6c517ed05.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b1f3549-7a16-4699-8391-bf79c2e3577a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ee380fac-d0f5-45ac-8de7-579d9259c7ec.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b3398513-f49a-4570-9a0e-bf5f2849eb6a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1faa9796-0875-4925-bd27-341e50ca61a4.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d103afdb-fb68-41d3-b1d4-9d7a0f6da68c.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d316cb19-edf3-4467-a2f3-650e11c0f86f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f674758-b142-4d0b-a32a-0de4c0a90198.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/96f8bc01-d17d-41b5-9191-f231688d9d0b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5f4556aa-5cad-4e89-b5b8-6351723d6858.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c5c165c7-e016-4176-a101-287a98cc9167.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dbc5967e-0dd1-4298-9a36-39c7654cdec9.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0b2820b1-7227-436d-a406-8562e5d54dd6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8a19ea4e-4385-4103-93d0-aa5f8f2c86e1.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1cb7cd68-0cf2-4f7c-8b1c-406f2a308b45.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81e0990e-63d0-4482-8b87-1dee16dade99.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd063a6e-ac38-42ed-963a-8b280e8d9b1d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/63c7b9c3-ef17-413a-a4d0-abf3eb2ebdd6.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f77a3d93-9bb7-4f1e-a93d-1012bc57d234.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fbc89050-bbc3-4150-81b6-0f74fdb21e6e.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2478a5c2-262f-48d3-b847-3e996450be4a.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/069725a5-6099-4978-b0c4-c28553e865f4.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fca34be3-74fa-4350-8278-9a4ef1346fe8.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9d9e23d4-dcf2-4800-aaaf-327648022937.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/10e9f366-9723-4eb0-bb85-b463f2a96b76.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb752330-2d85-4e88-b9c0-81a2553b7d86.jpg: 640x480 1 face, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/53bf810c-96fd-4fad-9d7d-98234cdd5a75.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/532a7504-5143-402c-8074-ca7da804f751.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ec4e0d17-e8c6-489f-b57d-89ab61457dd1.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a35f3b04-5142-40a6-8f49-83196cb0fce5.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/74f03f7b-57cf-488e-850d-f51c41402c40.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f46f6e5c-bf72-4d9b-ae81-789053ef179b.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/44ae5cdc-c914-41b1-bf0a-2aa24262743c.jpg: 640x480 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4433d0d8-df0d-4d87-b950-a8b49252b593.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d7b48e7b-82a2-4b38-85e2-1eec35958669.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a53b36c4-82dc-4565-a119-5c6474a56970.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6e5d21e9-3759-4f44-9e8d-7c504d0673d7.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cce482b4-8851-4b33-80ad-da9a718f4da0.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/78adaca9-9a20-44e0-a365-3c3a888123a5.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/204f8f2d-c4b8-4b1a-89e7-030e0026ad20.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/83f7a76a-eacd-4052-a325-62e5870eecb0.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5fa55c00-3a01-450d-bc6f-3caa29a80500.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/211ce129-5d66-4dd3-9a6e-3eba82a8ea3b.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f744f0de-6717-442c-8212-c41909e9bbea.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8032ce52-4e81-4382-b77f-044b6b536b4e.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d1e7c045-5a5f-4313-8c25-4f037d816b86.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/db53564c-931e-4984-9e1e-32c769c0df4a.jpg: 640x448 1 face, 114.8ms\n",
      "Speed: 1.5ms preprocess, 114.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2e1dfdc7-f003-48b1-996e-45eb70d17140.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2e711377-1eff-4e56-aae0-997e0a82a614.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/035a2765-0156-4dde-a912-21c92199f48c.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/93824c4b-477d-4c8c-9243-3e7f298289ff.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/82a40b97-1c54-4ed4-bdf6-76c1a48b1013.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/520fb12d-2366-4356-9020-efc7970fd6a2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5b73aebf-11da-47aa-aa72-ad0d5af6e577.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/76f6cf90-18a1-4c8a-a17a-222b8a22eebc.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dbb0682e-31bc-43f0-b9ee-67a332add3a9.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d6b8c27-ee7a-41f1-a20b-bdf455cfa2e2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5ba0f1b1-cf43-4ebb-ada4-35e044a84bd9.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d8b4ef9c-3d5b-4ef5-81ab-d207d61c895c.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb106c84-0a05-4ddf-bfe8-df176cd1050b.jpg: 640x384 1 face, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/317f7c04-bb61-4415-9024-2e7017e3faa2.jpg: 640x480 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d027002-4421-4072-abad-ba8673e9fb82.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8761335e-54a9-407c-a529-40d824358b33.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/30642975-0e68-48a8-ad97-7daae2e5039a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3ce00949-050a-44c5-b534-de35f133ea2e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/346abe78-19b3-4618-9624-f4358d3f93bb.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c060b0e3-ef4d-4217-9288-359345459770.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b8d039b1-0cef-43cf-900e-def161b6ffa2.jpg: 640x448 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c547c02e-9120-43ca-a940-66702fdd4183.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d25fcf35-d3b4-4101-9e4e-9b7d86c3f144.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d6657006-2326-4b69-bff9-d86245a40e5c.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/abf1620f-84c2-44d8-b254-c1a615ec5d5b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c4bc62fa-526a-4113-92eb-0786add212b0.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d2f72efd-648d-4ceb-b81d-d03a528359bd.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f7130876-6b3a-4fcb-90dd-744548f93ca1.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/94ad5f67-5f48-437d-bd73-00d40e297949.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/afcd06bc-5982-43fc-af5b-c08893afa11f.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/187f164b-aa38-4f4e-8a77-ebf41eaa69ec.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1a43042b-dac3-4e08-82aa-fb7c3529eafb.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9d0eb7d6-e6a3-43dd-a6f1-b5363bbb10bc.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/430ac8b9-bf3b-436e-89c1-14c70d3ecdd5.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0530fe44-5f58-4bcc-ad77-34f64c3aa085.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe346bbc-d1dd-4120-884c-2b39ec41f451.jpg: 640x384 1 face, 12.4ms\n",
      "Speed: 5.0ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7499b509-2556-4c0f-b27a-e6afa83d5dcd.jpg: 640x384 1 face, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7d3ccadc-e213-4c67-b1cd-fa1b23b42bf5.jpg: 640x384 1 face, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f29983bc-cf42-4f32-93ab-248cf082a3c6.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fd019a07-4530-4686-a908-d8b73b0def1f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ccf72dad-af93-4fee-a6a7-ba11663822ba.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ec91ed2b-38c7-4ddd-8d9c-aede828e906f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f28b6d33-b6d3-49a3-aaca-f5bc53aa1fa9.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c759f54c-4389-4bd9-ba1e-7c3f4216ba11.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/204eaf8a-6b4b-4f34-a3fc-3247a4520828.jpg: 640x384 1 face, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f26b7161-30cf-47b4-a7c7-4d6bf87f4d6b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d57ba0c4-5b1e-46ca-9e30-74f93056fa51.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/32971156-0b21-44a3-8b6e-153579b2ea43.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dc76983a-e156-4502-abe0-235b784bd895.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f0edf042-105e-4198-84c7-cb4c191a4644.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2db1e73a-b6a5-4d33-9e60-fedf5325d023.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d36a248a-5033-4ad8-91c7-6d938b604b15.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d57af10e-e4cd-4c94-b1a7-9ea63c857240.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/911aff72-296c-4c4e-903b-a3f7b239a25d.jpg: 640x416 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c2bc1026-2c9e-4f31-ba89-cf7b34060b19.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f316ffd9-30c8-4cd8-b220-f0d0c7f68d41.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e73c017a-fa85-4280-8916-e01dad50d8b4.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/359b1b37-0e93-43ea-8806-787c7efe4bf6.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9b229133-d430-4808-bd8b-3ba431acc87e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/163b2646-eda4-4215-9c72-7c1f618a5ad3.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eeec50de-c7a7-48cc-9b4b-520476d5bdb4.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/01bdb564-926f-49e7-a15c-7de5f84e6ecc.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9313b710-2281-4dc5-be1f-3f666fb94065.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f15058ad-1c2b-4a2b-b456-7ae1ae7283ee.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1f1dfc63-85a7-4ba1-b6df-ea26a2d3ef07.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/37e08d08-50be-45fc-ad9e-e21a961505ba.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/478ae131-c5ad-4006-a4e3-ed4f03370197.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2076b43b-1fd7-487f-8854-b66e0a53ba02.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/392243a2-6074-49d7-a8b2-5cc53acef44e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7d467e3d-ad11-4472-bcd4-7108b79302ab.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/38be33e0-262c-48b3-afda-17abc258f470.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.7ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a58461c0-146a-4f6f-a96e-cde34f66c2cb.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2cfb1aa3-5141-4ca2-98ec-897fad5e9b08.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3fec9f04-c4a9-4883-a917-51746a79a97e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8be2f439-44bb-4d5a-9654-7195513384a8.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cfaf2718-dd08-47b5-8d1c-89bfb18fb5c1.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6f657458-8561-40fe-8bda-c88a1350da9d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9ffd67a7-7c5c-43f5-ab31-7184e9180482.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1170a33e-0375-4cac-9635-301cbfd6e14e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2a694418-b08e-4d08-8d58-5e9dc2d2a0d2.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d31f413-ae6d-4a96-a3e1-1af114ffaab2.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7974738b-4375-46aa-8537-de1452d15a43.jpg: 640x384 1 face, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fb8bc44-5646-46f9-9bc8-c35661166adc.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8c977431-a74b-42d3-ad77-fefa24474c7a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c1a9b555-6853-4ecc-994d-fe94f00be548.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/75ba86ff-d627-40ea-809d-2d746cb058e3.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1921e105-c16b-40bc-94b5-644ad0f7051d.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/178b823f-3402-4df1-988f-24435b9aef95.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/15ee60d6-c7de-42aa-8a38-02be97e87365.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/34dc18c9-7e6d-4884-884a-275de87e8806.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/26c780fc-8c58-4a76-9c79-abc7a15efc49.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/77fe2f99-286d-4061-9707-b2ebb15524e0.jpg: 640x384 1 face, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3323fc67-b64c-48f9-8a29-f0a2c00abce5.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/98df3bf6-c8cf-443b-8fb0-f34b231ddb48.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/03279bf8-508f-4cca-a828-efb325c235ec.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8c93625b-8703-41bd-bc8f-7652f199008a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/03daa20c-2b43-4ae7-9713-b3929952cab4.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/038da264-1cc0-4202-b0b9-5985db68d891.jpg: 640x384 1 face, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c7ff034-9dd5-4f3b-8466-790a5f73eb11.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0c392ba2-17d3-43c1-bba2-b3f67dfe8941.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b165026e-a1f1-4516-a82a-30e9d7434e01.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b8b9091a-7612-4350-9bbe-0b620a75463d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a3055934-1b86-469a-9c79-57f2d3195afb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e1ede70c-215f-4cc9-941e-5e8377879ad6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/da19b1ad-57bd-40c4-b192-d0a26c340291.jpg: 640x480 1 face, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/87449d54-f97b-441d-b35a-a3da0026ce40.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1f614655-e1c2-4198-96b3-0e7a71a1f608.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dda81c63-c2f2-4cfb-8f29-99e159f9f903.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4d50b181-a91f-437c-963f-fef4f9c8b3c1.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a766abff-dfbf-4660-abc6-ca3a82991fab.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/43da0850-2f5e-4661-8bb5-2a718a3a6e21.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/711afb4f-d890-462b-97f0-d1072a3d5d63.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e7e260ab-5a7e-4bb0-8999-c8d4bd8fe78e.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/16055ca6-d9fa-4636-b35d-698fee961ab5.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe656f8d-2a57-4ee6-a128-25bff9571c06.jpg: 640x384 1 face, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a2210c57-84a5-4e38-8b40-50736b239c8d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/413291ab-06c9-4613-a4cb-4568c8e082d5.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c5f9d12a-967c-483a-a56f-87c029e6f1c9.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/46d32af8-b989-4e2c-acda-4ff5ea9a79e4.jpg: 640x384 1 face, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f6f242e4-c794-4421-b57b-fa11beca2bef.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d02fbd3a-162a-453f-a99f-6af94daeb9f1.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8ae51b8e-4c58-447c-a967-9885eb31f4d0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/822f8c68-d905-4dc4-9b67-5b800bb9cea4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dd2e48d2-d04e-43dc-a1a0-00d0089782ee.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f09046c4-b9b7-4c23-aba2-8096717e1301.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c3eff63a-42f1-48f2-a50d-84597d4b0ca8.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/457d3992-eb8c-4db1-9645-8cba0ea1de01.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e441e6e8-a382-427d-8f06-eefd9fd818a0.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d9293c7-1c8e-4af1-b5c9-65e71fe33b74.jpg: 640x384 1 face, 6.5ms\n",
      "Speed: 1.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b42ea945-cb7b-49c6-b35a-0f3f8399a594.jpg: 640x384 1 face, 12.7ms\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/41aac868-3f70-4950-bc53-eeed11d4e551.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/014da923-81bb-4295-9aee-f5583900c5d7.jpg: 640x384 1 face, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2a4055db-3700-4a90-94f5-8bd493822112.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/53a13b78-7f6a-4214-950b-48a3df5ea82a.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/527358ff-1adb-414e-8901-066c2026dc69.jpg: 640x480 1 face, 6.3ms\n",
      "Speed: 2.1ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/16ef565f-08ee-40ff-a873-00186f5832ab.jpg: 640x384 1 face, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/708bc29d-a04f-4b9b-8966-e03267514526.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/df87c692-6015-44e0-b97d-a7cdc23a931b.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a9916de7-0a05-4b9b-87f5-8879bd4c2154.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7ac12ef7-772a-4561-b194-7ebb534f6867.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ee0e1140-42fa-4f0e-b19d-c9ef308a0470.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ee9409e0-f25b-4a22-b316-71c98e49f502.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c425637-e385-4832-8a08-f5b3b656b951.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1b30dda3-c8a5-4268-ac25-99a74a55713c.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d2d76b81-52a2-468e-af7b-ec5af5c54f5e.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/47b77778-e63f-48af-bf28-4e5a2bdb0894.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ffe27f48-8b1a-4855-b409-48fc1432b164.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/21e6d9a7-2105-496f-8ad0-b986876e7abb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7d4397a5-b5ec-4030-aa64-253feea7c8aa.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d9265bad-c255-4f1f-b653-aa0e3b361e75.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4c25e3a5-c3eb-43f9-a89b-8b59320d71a3.jpg: 384x640 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/51e9b67a-84d6-42ba-9f90-cdb4e9077e71.jpg: 384x640 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/13df0b61-b5e5-4668-9877-1fec8e872088.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a0cf773f-869f-4d34-8ce1-a914e9983b3d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6aea4bb6-895d-40c8-8d7e-92d8677cfe0f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1dfd1f56-e4e0-419e-8848-d0f0873dad5e.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6685dc43-1fee-436a-bb70-615338bfcf9f.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb05c949-c24a-4d69-8c8d-c7e7a20c3e4e.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fbe37341-ef5c-4146-a4ad-e1ddfd7a382b.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/602d1920-83a7-41e7-a300-dbd1e3f5301b.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ad718439-c320-49b1-b730-453dad278437.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/89168e63-e6b1-44c1-91bd-8a65fe5fc28b.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/45b1a81a-14a8-4218-ab24-78f87fb431bc.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.8ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a7b2912c-befc-4002-8f51-f4f81fc0de0c.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/40b40293-d108-4225-87d4-306bca750cff.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fee2f79-2ce6-4f5d-9211-7580754f012b.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1f0b4659-27ba-40c5-a540-582066b8d26d.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.6ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4fb10a1-0e62-4fa5-a1b1-93f50cf0ec40.jpg: 640x448 1 face, 6.2ms\n",
      "Speed: 1.7ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b56d6bb8-ee47-4d7f-99ac-52f5a1b38c5a.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/088fd2cb-d091-4ef6-99bb-130b08517264.jpg: 640x384 1 face, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/666fb478-af32-445a-91ab-b2f94ab1f075.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2a6ac96c-7f50-4f59-9fdc-11ddce7179db.jpg: 640x384 1 face, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8f0f90ce-989b-40d5-923a-f3057a127106.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aea2e2e0-5fe5-4a9c-85f2-d15412e55dca.jpg: 640x384 2 faces, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1f0722c9-aa35-49ff-8da7-33a06619b558.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/09b5e9c3-288f-4010-aa92-e3a58e4a040f.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b2b4a733-9800-42a8-8db9-4c44a6f645e0.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/94082808-71ab-4c4b-b7df-c1ecfb193ff3.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e9d8a31e-0071-4d35-94f7-c20cfdd042f3.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/979382b3-8128-4252-a06f-5eda7c09fc8c.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1dbd0bce-9b79-4ba4-9a6b-1afdea706ff7.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/660c3534-09f1-43a8-bf54-37279883e408.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/764a5adc-9163-45d1-943e-1f0db5116594.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dd0401d7-b598-4edf-a27c-1adad33002fc.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0352d5f8-e804-4ead-b284-d742b426afc2.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e3a7d684-0379-4163-b82f-91b8921729d0.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1584a451-c473-413e-8df3-1b49ec75436c.jpg: 640x416 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5ff194ed-0b32-42cd-bdd1-fe80a5420e81.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a4a523c4-4906-4d7f-ba99-d76861c4f1e7.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/06df77f0-f5b4-418b-aad3-04f8415cffae.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7be360a1-a04d-48c5-8ac5-adfbc2b565f5.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7e95bca3-d722-412c-b2e6-539ae4d1da9e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/47fd5ccf-cd7a-4321-a48c-c339276c6e5d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81d959c5-9c13-49c3-8b5b-8c8a5604f98b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d3fc7c0f-88c7-4ed5-a2ab-5c3c522cae95.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6a23da6c-c04a-4d3a-b940-58038e990cbc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0eb929b5-5c95-4ee7-b930-692206d2290a.jpg: 640x480 1 face, 5.8ms\n",
      "Speed: 1.8ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e53f2f62-2e8d-4d87-a7d9-b50e51de4357.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/04326192-5943-4697-b732-62f39bbbfdd4.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f80c94cc-4494-43a4-af76-12c5d9dd38c5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/daadbb88-6b50-41e6-9121-125e59a96284.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/36a7d4ae-9bf0-4b68-8a44-756e258a21be.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/98ef9bdb-13b3-468c-bf6d-ed82b58f0835.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dfa1af2a-6d9a-40f1-8ad5-9844c6db1352.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6fbd553b-29d6-4cf2-b50d-a772684aab17.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/390d3c95-f0ad-4f01-8a51-5b8b1b5adc5d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/45bd7432-a09e-4af5-b153-afaa63a95757.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0b2c7e76-55fd-49a9-80cf-012fb76a63a6.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/88ccc9a8-296b-46a7-80ce-e4f59d36d36b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ba49223e-19c0-4081-a2e2-5db82a788a99.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e42c1ce2-1d40-4aff-8902-9f160164556c.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5fc0cf53-16fd-4581-8fa6-a15bc19db3d9.jpg: 384x640 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3be11dba-cb9d-4357-8986-5c8cc8c3985b.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/232e4694-9de7-4e16-a0d3-b24670619129.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7f852e2e-bfd2-487a-9b23-3ad260eb4682.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9e31bf6a-342e-439f-8295-137e6841977d.jpg: 640x448 1 face, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7b75ecac-48b5-45aa-a3b6-3450179bb1a1.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7d8edd9e-6f34-4030-978b-8399f72f7234.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a9a653a3-5401-4136-b8d7-010851bd0bc0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bf91c540-448d-4519-989f-a0df1db1e111.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9a1f03bb-f4c9-4ce5-b013-646db31704dc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/83c5b201-2bea-405e-97df-37d644a59426.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/53ed940c-d68c-40ce-97a3-f7e48861873e.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6893152d-768b-46b7-ad07-7d116e967996.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/60fb8370-e5e7-49bc-8903-0f018b2ec278.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/128aba45-58cd-48cf-aa32-519a03613f0f.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9c5c0ed9-6c2e-4633-a0c0-b5a4802a3d29.jpg: 640x384 1 face, 18.8ms\n",
      "Speed: 1.5ms preprocess, 18.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/041a1b78-67d3-42ae-bdeb-2c278e7b1ec7.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0cb7e1e0-6e03-4b65-9e9a-ac43afe7c51e.jpg: 640x288 1 face, 137.4ms\n",
      "Speed: 1.2ms preprocess, 137.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/73269023-fea6-4b75-94c4-96d9201fc422.jpg: 640x384 1 face, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7828a112-87c6-4b49-b11d-39f2200f88ac.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d2585cfb-d168-472a-841f-6d52be98a411.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5e310df0-a572-4179-b29d-39122e7fa13e.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/00465893-d184-4147-b870-66ca63c6996f.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bdd9de25-d397-45b5-a1f8-7ad9fdea7a96.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ce49d8e9-ae83-4e2c-a8e3-1a5ff6ba904e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02e10c9b-de37-422e-9160-8077a922873a.jpg: 640x480 1 face, 6.1ms\n",
      "Speed: 1.8ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/489c1562-8a82-4cf6-b38b-51df6e6aeb6a.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/54754967-6f40-43d9-ba5c-0c01f55b9491.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/648f4566-7e62-4173-af94-c8cca5fe34dc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/714b0ca7-5944-4867-85fd-7a50b1904539.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/018b004b-23f9-4de0-a3f6-9240d54b882b.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/94db7fba-0d0f-4cb1-a205-eeae5476c8cf.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c19737af-fdab-4230-ac39-dcdf147d6009.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/84d46226-e3b6-4543-a004-4c82cc7060a5.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/19e3b3e3-c3e7-43a7-94d9-43fc0ad2fa94.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aee6b85e-7bd1-4d38-9af3-8ceaeeab0fba.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/107c43da-d133-4e37-903c-3c0f709ef0a8.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa13aa21-4d37-450e-be29-f153d1148de5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02d7bb24-80be-475c-b3a6-fb8a45b394fa.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/941f4719-04a0-432c-9dd9-e46f2f01c9bb.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a1eca755-2c6a-4823-8b4d-77f2a2169609.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/15bd778e-f2ec-4d18-bc6f-ac255e8bdef2.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/37767ecc-1cad-4f01-b0b2-92e46a01add8.jpg: 640x416 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/66f3f0d4-d708-433c-95eb-6fa982df7078.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/307dabc9-52f8-4b9f-a360-5297b83f2718.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/300f0f82-9c9c-444b-ae71-b6608ae8b5d0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/71b64855-cf02-4b77-a0b8-5e150d67c0dc.jpg: 640x384 2 faces, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a00b6e28-9746-4444-a807-3d873c57d57f.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c25d10c4-efc5-4b59-b53d-b3e90323adb4.jpg: 640x384 1 face, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2406357f-4532-4ccc-989a-09c6837dbb57.jpg: 640x384 1 face, 18.3ms\n",
      "Speed: 1.5ms preprocess, 18.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/268431ff-2953-44c9-95f6-00af63bab982.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c95da8d1-87d8-4f5b-9c91-44c9c87c4b90.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f139a307-ac7f-4c61-b9ea-0b5274514455.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe344cd8-f4f2-42ec-bbd3-7bbf9276406b.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 2.1ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1e6d6814-bdab-4d62-a933-ad7c9d590cbe.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c941db7e-06fd-4150-80a4-b1afc34701dd.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b21594d6-2996-4989-8a6d-a20e3f10b6c8.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb83b7f0-7000-4219-9e72-9339927642ae.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6de624a1-af5c-42cb-8b44-e777b1e4f3db.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f32a0f9e-0c0e-4f25-a631-aa98a15b2ded.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e8a874b3-1cc3-4a88-ab3e-a5d670df4c83.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e4c8bec0-9460-43c5-ad17-ba6e08523204.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/65a0bba3-4fd0-42f1-ab79-2d5a317e6572.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a5358fd6-5319-461a-a287-1ba8c6773d80.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b900aac0-19d1-45a6-aff2-bab1fe25d117.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7484831b-dab2-4807-b353-8536e6d75701.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/26e18180-22be-42f2-b515-bc6f6bba755e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/088e3489-4ff8-4c8f-a71b-324c9c285657.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d6c0e37d-0de9-43dc-aacc-15a2a4155fc2.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/df77445b-d9ef-445a-b0de-8df96d727984.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd305a71-5a3c-4000-8914-8373af45ceb7.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5abfdb0c-b74a-4460-8da4-b28d3e724199.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8b4d1ac4-4b95-4d43-8bbc-4ee789255ab8.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/35c0c061-774a-4596-ab49-0b0838efdbf9.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/23fac11e-92ce-48fd-8501-e869b32376e6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c074bafa-f7dc-493b-80bf-00916af82de7.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b99d211a-0574-4c51-9ed3-37e77ba992b0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9303ca17-1ad9-4278-87f8-574899c7d20d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fd547a39-a423-4e07-8ce5-a5cb236e2281.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/705be595-0f07-492b-b40f-8926346cdaca.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5b933973-d8d7-4dbd-8d9f-a3028de8670a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8cfae4ef-e011-4b02-8116-331ac01dc53e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/92cc9e79-1602-4fda-a1e5-777ade543d7f.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/66ac6584-0632-47ed-89f3-a139d9006e03.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/46595640-7ecd-4899-9005-fcf79923e908.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d8bc454d-cb8a-4c6a-9aee-62c235c39e5e.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d68c22c8-6939-47ee-97c3-baadb7c0b765.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0a28b393-f889-48f3-a47f-e5001ea15844.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/84dfe404-bf04-42b4-be06-cf7276e596bf.jpg: 640x384 1 face, 17.5ms\n",
      "Speed: 1.5ms preprocess, 17.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/471db68e-9216-437c-8895-f7aaec1f80bf.jpg: 640x384 1 face, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c59ad200-7d40-48ed-b332-09bc154ed574.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6f6e8a8a-690d-4576-8a89-6c329406c20d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/39e56d65-86ae-432c-bd23-048a17864d97.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/790ca876-2708-4e92-be55-145eba077d19.jpg: 640x384 1 face, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa7608d2-2e04-4239-9140-1f0721f3a1ef.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/952e71f4-e911-4adf-b4e2-06a0a16b6c03.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4f849710-e3b4-4639-aad0-628e2afdac6b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/324398ec-12aa-4d2e-a7b6-2b0b86c70b88.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/59ff9f64-9147-4d2b-b971-24ba868957fd.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c07de3d9-bd5b-4173-8e24-9a9dd1da2a34.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c8803fbd-1e74-4925-befc-a60e2bceead1.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d7c4d78-56be-4b59-bb94-d66c9ed0cfde.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ce94fa5a-ad1e-4ba5-9035-34edb930a382.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4c6541be-9f4b-4826-80f1-2e38e259791a.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/de432579-5fdc-4b09-bf04-a3ca4fa100cc.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c17d0aa0-36b6-4d59-95ae-76f7abf2688e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2fd1d6b2-e031-45ab-a3fc-de05603383b5.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c1a1ca28-c3ea-4258-9828-2f5a7a3e114d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d97a71ff-59a6-4b21-b8ee-975f1a591624.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d6861576-b384-4728-89f9-49750e42ccd9.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd8490b8-a706-450d-a509-c3b7457dcf7c.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f3062cda-641b-478d-b3e0-65e880ef9d2f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0728437f-f5e9-4fff-8687-3301750702d7.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8b63562f-dd0c-4cfd-8c3e-2ca07255171f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/31fce805-4eb9-4fcf-9326-df078c04c2ad.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/14dede2e-2052-43ac-b410-8221673dcd15.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1a4b72b6-f94c-4db5-9a9a-1ac0bd8d06c4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b0425b2b-3fdf-45c3-ba37-1819d67ba882.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb18f8a4-c7c9-4fad-aa97-18a59f99a63d.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/23616ff6-ecae-4995-a5d6-b7e1fa10db68.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e5915eac-b62e-45a2-9c8d-39607afe305e.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6c43db5c-c789-4e78-ad03-d3611989c906.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9ff8ffbc-b4a4-4566-93a9-45f88f23a6e6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1d13ea5f-4fd1-4140-947d-852a135be915.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1020eb3c-1181-461a-9c17-cb60acb80c20.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/11d0f06f-cb82-4842-bfdc-a116bddac85d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0250fd7f-ffdd-4b3a-a278-25cfbf9df392.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/88a29b37-121c-49cf-bbfe-5bc0aee3e0e4.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/689ada19-b5b4-4408-9b50-833400a578e1.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/929c3e34-2f68-413a-a0de-fe5ea1554a4d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed2c071f-1626-4481-9c96-1ca1e2e39083.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c2b938fa-2246-4e25-896f-58eeede5b7cb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/df64d862-ce99-470e-8a0d-5ead5b69c414.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dc1a775a-250b-4747-9576-866c7c0620ca.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1a6108e0-413d-492c-b6fa-eafde70b649c.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b426e388-66a1-452e-a051-d2a32ca8d75b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/da13dc9d-35e8-4511-804d-d09a475e7b23.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/656f49af-096b-42fd-bc43-b627decb5155.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a8d1b2dc-5fb8-4441-b7f2-8db3491c72da.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7ae75c21-2cf9-42f0-a1ce-e155135eab20.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/78c04121-30ff-43aa-9b59-2d5ffe17beea.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3ddf5d49-d722-4642-80dd-9890a30f4d81.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/df1f034d-e37e-42ac-bb49-a2ce7c1c1a51.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2a89776c-563e-4bd4-9393-815b570e323c.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1b2453df-2d5d-4e3e-9b4f-7f260c75082b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa3cece2-5b1d-4ef7-9364-2eec42bcee34.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fd76cae5-5031-4030-bb18-64ee0b8a3ef8.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/07a674ce-4ab7-4068-89bb-7e311f0502d4.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9efd31be-6227-4b82-89bb-f5aaccdde534.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c0093bc-46f9-410a-9904-4bdd6df00205.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/912d4194-547c-4dc6-bfc8-3787ea7dc3f7.jpg: 640x480 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4bf3466-a77d-4737-b3be-383ddd844056.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f19a4859-eaa2-4a4e-a27c-ef47b497c11f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/48b883c3-6f1a-4472-86b2-819996a6bf55.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02852384-cf48-4af2-8c61-97a8ae7316d8.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/65d82345-6146-4cb3-8cd0-a327b2fae645.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/937fcdc1-0c16-43d2-9a05-6c4081aceb94.jpg: 640x384 1 face, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc2b047f-138e-4955-bd6b-36d6abbabfbd.jpg: 640x384 1 face, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a1f0798a-c183-4022-8fdd-93e6fde53e53.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d0d6558b-8835-43e9-af18-5c465389fc27.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/949c7e63-5814-41c0-9c48-0c3ecd44a2da.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f0538a2-a3aa-497a-8348-95ae2884d716.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4270d968-7dd2-4c81-ac96-84d1aa38a680.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3e9a85f6-35c1-4231-9761-d6ae57f3ba83.jpg: 640x480 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5e4a12ca-b975-4b93-8fdb-b0d621071044.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d22782d0-8525-449f-a1cf-4f294bbab31b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/956fde81-f315-4c9b-ba86-310d4d46f666.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/34ad07cd-5e70-46b1-9760-3255e2a28b1b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ea46b7fa-f9d2-4e3f-9058-582a0532cb3f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8624b095-2527-4928-a3db-1437eb87f665.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6594cd25-9a89-4876-8061-7e5a95a9498f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd58680f-ddef-4ff6-8f19-46d1810a1ce6.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cec80634-fd57-4f29-a0df-12d4d8afcd7f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d5b39ae9-79f5-4d53-8551-863fc3bcada7.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fce1c8a0-5cb5-4b9c-99b9-559f04277dc9.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ddae14a6-81eb-457b-8920-6ca0ba602106.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cc50f20f-18bb-4a79-bb7d-0b49c9047c52.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1fb262ba-e350-4935-aa03-ad2cf6a22f3a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/daadfdb1-1e04-4dde-a63b-dc6a194fe674.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3a973457-79c5-4c72-afe0-961df866bc1f.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/50be5819-bec4-4964-a364-9b1109588c7c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/98f507c0-4de1-4fb0-81bb-89fb0677695d.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ac8881c5-bdfc-420e-9bbf-131dfb9a17ff.jpg: 640x416 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/de72e39e-f146-4c80-82b4-cea78fb02f73.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b1c1963e-4876-41f5-ab89-dd0c80843031.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/69a8fc1d-8fe2-44f4-9582-625070299cf0.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d3a18adf-3e75-416d-8f87-152d79a68ed0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8e7bc3d4-d0af-4b8f-83fb-d4d65dafc53a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bbb802bd-1e47-460a-b711-b22bd2376532.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d56908a0-5a4d-46c5-ac06-f0bee87da65e.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb2668e3-3ac6-4679-96b2-d6199cb66a0e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0d68e8e2-7367-41a0-9df5-60272c97369d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/77a79ab9-f4f2-4fff-bdec-e221dbd33a78.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e87020cf-8c78-482a-9cb4-81a1deec4d1b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/be723906-6678-4dbd-9f96-8799a8116004.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d231a778-e752-4dcb-b317-2662addce0c9.jpg: 640x384 2 faces, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/64ae957f-4d8a-416d-b4cd-68359af76dd3.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b666c4ab-b7d2-4528-a1fb-77d2b69c00b5.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6de0bb24-a4ac-46e0-80df-42ab3e0733fb.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fde6b186-c576-4162-b7d4-152ea47a8a07.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/329aa630-7a4a-4c92-838a-6547b12ae77e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a14085a1-948d-4bd4-b199-43c88b050965.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc9a839e-e631-4a6a-9227-d024e545eff1.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cf48038b-01fd-43d7-a191-18c74cbc6d93.jpg: 640x416 1 face, 15.5ms\n",
      "Speed: 6.0ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8b3534a1-86d5-4cef-baf6-df4205988722.jpg: 640x416 1 face, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ac1efcd8-9285-4503-a8d7-fde60b724995.jpg: 640x384 1 face, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4c5b0f3c-39b3-49a3-8959-8184aaaf5e83.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f381be86-c9f8-48ad-9a8d-ad095586bd1b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/178fc677-50e9-414e-8cbe-28962294f9c5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9c5260a5-eacc-4720-9095-e7d830d8f1ba.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7b5cbd27-007f-4348-9d9f-c26aa366e787.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9f672c7d-a644-4946-a3be-634835806292.jpg: 640x384 1 face, 7.8ms\n",
      "Speed: 2.2ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/79c1a5e9-5350-4c93-bb71-31ed9b3f20e5.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ce1da5d6-7f59-48e8-9a67-67805509f047.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aecbb0f1-c7ba-4ef2-b119-8c58432a2acb.jpg: 640x480 1 face, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c5ba5fb-6016-4514-9fc1-c9c217c34167.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4be6baad-3c47-4e31-ae3c-44710ac8126b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f2ae9f8-28f1-4110-ad4f-d355343189e1.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/57533336-2d7f-4201-89ef-a94d16259e1b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/189a7b2c-70de-4aba-9b33-3197461d836a.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c6ba4fe4-03ac-4244-837e-17e6aed8fb0b.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a91233b3-e6a2-42cd-87c3-fc20b3c7d055.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eda9907f-4bd7-4049-a90f-8581a9630887.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/18d4ca7e-ddc8-453b-8e65-0aa8549fbf6b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b6c8a864-acb6-4112-8216-0f04285d44a0.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2472a45d-3489-4a1b-99e9-5e9762da6ca9.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/45fe5bf5-acac-4ee9-a823-6757ead2752b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/47c4705f-981b-427e-93b7-0ab2a8f17131.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/30589c79-ce35-48ad-8eb9-8dedc3d785de.jpg: 640x480 1 face, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/32492ec5-2d14-4202-b2db-55d9264c2a64.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b719f1c9-5c83-43de-8a32-8d50ba59ac93.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dc4d0860-6c44-4f8c-a854-4178fe6a6207.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/11ccd554-ca71-4c72-91ff-5141d9dcafd8.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bc4ac23b-8ba1-45fd-979f-aa44c8ff86fe.jpg: 640x384 2 faces, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ebf7e285-cdb6-4e64-9207-61add3184263.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e9c5af01-aca2-476f-97b1-d6c1890a7723.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/86202bb7-a535-43e1-90b2-1708272f012a.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a4f40f17-ca68-4cc6-b87d-864e9f6f07d3.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/434d5f92-3adc-4f50-baec-794c804dd06e.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d9b871e1-40e3-4157-8ce9-cf414d01f264.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1603a80f-e4fb-4ec4-b3d6-c68fd75989dd.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/183b0455-b9f2-4b02-94fb-08d9b9b34e80.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d3d1d74-d6fc-4850-a273-909b50858345.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/586eae41-24a2-4b2f-a9ce-b43a510b024f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4f7a05e3-2b4a-4bb9-9875-9d6019ca49ff.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/21472883-5b93-4596-bffd-83d0f3ae50c3.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/22a54148-a1d8-4e83-afdf-c87ca7531046.jpg: 640x384 1 face, 16.4ms\n",
      "Speed: 3.7ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e1d2b4da-0647-4e0b-b086-da6c7226aa47.jpg: 640x384 1 face, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/37c5f1c4-f7dc-4466-8432-2a893d782176.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/15957882-db51-41aa-92f0-03be75337f35.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/150a1d77-6d63-4e7e-b356-888edb5dba26.jpg: 640x480 1 face, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9a3fdd6f-7f70-4328-9dc6-4d0a3d86674b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/685383c5-92f9-41c2-b29d-fd7907f80159.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b03a2186-1bc1-4347-9631-a8c7f6517c39.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1af42bcb-d6f1-4a97-a117-5cf8b5d34013.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e26567a3-277e-460e-9c77-911a89f1a528.jpg: 640x384 1 face, 5.3ms\n",
      "Speed: 1.5ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e5a93c64-cf02-4f28-9d14-6ae18d99d136.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1038cc8c-00d5-4d8c-80d5-315cc0f7187f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/43ecbbe8-3c94-4304-83d1-ca0502d47d5a.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c5f6326-645c-40a8-af01-9acb7a1d8d15.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2e7f7e28-cfd2-41ff-872c-31432cc5c18d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d396c01f-aa81-45dc-a7ea-2742f0bcf985.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8bb00fde-28b2-4244-8d47-f895876f0a26.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eee7c5c6-c594-4d00-ab86-cc3ab35570f0.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c351be84-b789-48f9-a88d-1d844617ec02.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0c96bcdf-7b53-482f-aee3-9e303036f42f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/596643fb-1ed9-44c4-9efb-8cb4e93f6058.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3bd4bde6-36a7-4624-9292-5cb23c3508e5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7b84c153-27e2-4378-8fac-8ddd8c7309cd.jpg: 640x384 1 face, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/49e0b945-7984-47af-bb00-b98f79bee45d.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/93ec8fbd-b16d-4578-aa4f-c64347242d21.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b1ed8b2a-7a75-4379-be01-1cc2081fba51.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3bb51872-3781-4372-817c-6635f996ff0e.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/629d2f4a-d7ae-46f8-a575-b52008e84224.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e7b64e35-2442-4fbf-ad92-9ccbbbd7b386.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/36b7cf57-ef2c-469d-b9f4-8940613046d6.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2ce55a45-3c45-4491-b063-5988a6cad884.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/33d0d020-27aa-4440-8f7f-c6f81e8b7c3b.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/00a72824-af9f-4d39-968f-531b7da1b94d.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/be284f0b-1e71-4df7-b682-6a93272510b8.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3c16cf97-a001-443c-891a-2fb20523d151.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/845c3571-441a-4d42-931b-09e9d6033267.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bea3ad8f-14a8-4979-826d-634786a631ed.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/072b037e-1cb8-481b-9971-c98484fd07a4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0b8c0a5d-48cd-4203-8e46-78c21fda38ea.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/06a8678b-9206-49b9-96a6-959add053b1c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cea77eb2-ad43-4428-aabf-f8c9b66c9630.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8b826491-6d25-4d21-817b-bf85ae4dcb2c.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dc628d0a-7dff-400d-a3cd-c8a8726f499c.jpg: 640x384 1 face, 16.3ms\n",
      "Speed: 5.6ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/01729666-d874-4dca-93a1-1b4ab9a7cc61.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6442f61c-e9db-43dc-8598-de6d95e9acd2.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a38bb4fd-785f-4f03-a8f5-abef73562979.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/24b74f73-d0d3-4603-ad01-073181ca55ed.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/01453672-12c5-4d78-91f9-9965eae496ed.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ef42994f-7674-4238-90f8-0d6fd60166e4.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/93895b12-49a0-4122-9a2f-e43c31231307.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cd4a7e3f-4b81-4a0a-9009-dead962ef0e2.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/31d1c448-05ec-43d4-a580-6ecf95e40755.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/17f49702-ddea-4014-b3ab-1618526c3905.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/023d4f42-c64d-47dc-aa39-41da7888bbf4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed2343d1-4d40-41fe-b799-31eb09155e7d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/91c65d84-012c-4090-9243-931d0e8f7565.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f47b2823-38ec-4e13-8960-6a2cf8a242ee.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/30c06d53-1261-4089-894f-83ad658f34b6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3618575b-0d15-4dbb-9232-1ba236e5709f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b28af9b8-785c-4db7-ad79-cc9052351674.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/acbe754d-69bd-47da-b6d9-400a18cb07ab.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ecf61e6d-b1dd-44b1-9a8a-dca5d2f5d07e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/af73dc6a-9393-4be8-9b2a-3dd4cf5ea9bb.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/120738ce-a87b-4d2e-851d-1369fe4d4dc6.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ea0f2266-a7d5-4591-9a7e-9d7a0730689e.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f97b0d5c-f212-4aff-b55c-a802d83dcc68.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e5ad5058-769c-47de-9325-8ed57cce3dc0.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/93a9afc8-342c-43b5-85c1-a4941155e97b.jpg: 640x480 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/44bb3397-f1d6-42a6-8428-566fa7707ecc.jpg: 640x416 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d171460-5f13-40ff-8007-61bf3c598bf2.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4a11a881-29e4-441a-a28a-aa5d76612a0a.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4c759f13-8ae9-4ffe-82c2-ae87a7c632b1.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4251d0bc-bbd7-4cd8-9cac-3f159b149fd4.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5d79d897-76a7-467a-8737-33bc6fcad773.jpg: 640x384 1 face, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0239dcd0-a138-4582-8d1a-071e3f6f9577.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a7681954-2327-4ff0-b8b7-5c6e18e9bf56.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b6924e88-66db-4a47-ac86-61a29139a552.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/71844320-70c0-43bc-8223-69c30819686d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fa93ed42-9540-44f6-8bad-b4c3917e2e04.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fbe780f8-9949-4848-b42e-eb83378cd29c.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f690a9ed-e968-40cc-b15b-92d6b8a91350.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a6859a27-cce6-4689-bb71-1860aeca8c95.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a4cbcfc5-00c2-49d2-9ac3-15834f9833b4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3bf49055-f267-4be0-84f7-3c30eee931e2.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a8cf3915-e606-46f8-8306-4334ff9ee757.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/61eeae9f-d657-422c-a5e2-b1d98ad3d1d9.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f35ab97e-7c9f-4efd-9859-94a6589860fc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d9fc7656-281a-4493-a506-d8465c31c436.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/03d41b2b-5988-47a4-bee4-8154a02d141c.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/32400f04-15f3-48a5-a277-942ceb865f45.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a229e8a3-076f-43e1-ad90-6e8de6e8284b.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/08d32a7e-88e9-48e2-8324-035245b2f342.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2cbd2f37-bfd2-4635-9ef8-058f8620bef9.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b4c559e2-0959-4871-b3c8-ad8542a9f73d.jpg: 640x480 1 face, 6.5ms\n",
      "Speed: 1.8ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e7cd1712-92a9-494f-b9bc-4538912e563c.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d67b9036-35a7-4ca8-865d-bfad3082f0b9.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3b291e7d-76e3-4439-8671-d449d7933765.jpg: 640x384 1 face, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a979eff2-cb62-4846-a981-c80ff51f0f4f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/11af3b13-3458-415b-8483-b7ced34c4cb4.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/60204e7a-0045-4f82-8d29-5f96e4a62cac.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/96a55740-cca2-4c10-9156-94e819fab881.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/25f6ae55-8784-467a-9d46-c52e32cfc1c8.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ac381e35-37ea-4063-959b-a22037aa322e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bbf2a104-f595-4667-82e2-43b2c35d7955.jpg: 640x416 1 face, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d486ba73-bc5e-4014-95fd-e3b7658d9f11.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/31a8ec07-ae4b-4386-98f7-7607f6ad13a0.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8a333b9d-d17b-435c-9a38-81c0c84ac179.jpg: 640x480 1 face, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9871a51a-6c7c-49fe-9d0d-4367b1f9562a.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f8791def-f557-48eb-bbb0-14405ade9ee5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81369940-e619-46cb-b6eb-97071129f2ec.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f647c4ce-2f0c-488a-90e0-55cbebb4896a.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3ccc686f-d874-4389-b56b-b749e902692c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f0cf63b7-9819-40c3-a37c-378f6bd5ce01.jpg: 640x384 1 face, 5.3ms\n",
      "Speed: 1.5ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c9a73632-210a-47d4-81bb-17a7b0992591.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3576764a-2298-42c4-b995-5a2519207f06.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5c3b2c83-0c30-4f33-990e-53d24ff6fd3b.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2abef7af-51d9-454a-9584-b7d006f4825d.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/56fbb761-bf6f-4001-ad29-0e9d9c542be5.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9b143665-7d05-49f2-ab92-eb85befdf936.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b5df6423-0a66-4f05-92bb-fe68e53281f0.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b0c57f52-96e4-44e2-92f3-056d5f6068af.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0a18bc40-a52f-4b85-9d3e-2a4241bb8438.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7121e74b-d355-43ac-a6d2-c7ec69409817.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3e350432-4935-4bd9-a00b-b47e29eb26b4.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/426582d2-4a11-40b4-88f1-3bfe9300315e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/187c7ebb-d751-4107-8757-053faa332a4a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1be0484d-cff7-4517-847e-5c699e2130b7.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/20c69a79-6bea-44bb-b5cc-ae2d046d09a8.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/58657050-3471-4e4e-a6dd-8df029227905.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1d49d67a-fac9-48db-9470-b13a114d59ea.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c371398f-d590-4beb-9cce-50485d906ce4.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a5c240a1-eafc-4e16-a9c1-f9a243248701.jpg: 640x384 1 face, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a9154c66-f124-4ace-8f61-a0c6b846cfe3.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/708371c8-ec7d-408b-8f13-caafb0fb56e4.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9fe2d16c-ba00-4285-bb1c-5d12af91f70f.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cba9c1b1-0a80-4f3b-a4ce-bb0f6715cad0.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bea69ef2-9518-4aeb-8263-7ae55ff5c7c0.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/61bf379c-b991-4dca-b695-cca1169b457c.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/60ccf2dd-049c-4cd0-bcef-d4b489ee1768.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d50f2a20-bc33-491a-9bbd-ec2b38ec187a.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cabda6de-e961-4098-b84f-494224efd6a5.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a72d5025-ab75-4590-b73a-3444fc68987e.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/54a0fd15-b003-4747-bdb6-f54ed0821c86.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3400ebb7-77c3-4826-9604-3547615efa93.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4d58e38f-5599-4c51-a5c6-fd968952e91f.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/63515092-5d73-41d8-b4c4-d4f46cf23309.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/90856c7e-e82a-4260-bcd7-9609bb7f3e2c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e3627915-e8c9-4f74-b31b-526a1f077b1d.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/be433afe-6d39-41b7-8c3a-17ad7d6d3420.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c942d9ef-f130-4693-9cfc-35896b3ad560.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2fb22fa3-dff3-46c0-816c-24b0bcb1617d.jpg: 640x384 1 face, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f037ab1c-c6ed-40b2-9f8d-10d3b689a720.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a5b6c8b8-d8ba-4215-8201-13a5dbf79183.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4a5ab637-1279-41a7-9e92-e20565b5665b.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/59865cf5-7f35-477d-9697-a52b4e476635.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cf272303-845d-4f15-a139-aae2e118bbfc.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81324533-7d45-4c5b-80bc-a33306180170.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4cd98ad4-b552-4979-86a3-353f6e5d8cf1.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1c43c04a-1566-4f49-9cdf-e9e4b7e035bd.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bfc389d2-415c-44c9-9307-d63e2ed4873c.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b0c9fbf9-ac57-47a3-bdb9-b23f2c445fb0.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f37f6a64-e549-41b4-9f1b-af3a59cb71d9.jpg: 640x384 1 face, 13.5ms\n",
      "Speed: 13.9ms preprocess, 13.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dee17d24-fc59-4e43-90f5-31ef07060a11.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/31ce479c-9053-4804-8351-025118b35415.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd05c06f-b2a9-4680-9837-289c2601295e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d8580876-c4fe-4867-8985-28ef70badee6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/07b2116d-38d1-4663-a703-493596ac371f.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe16e876-5260-40cc-91c7-73bf1b8bdc2c.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/265aab05-fe86-4eb4-bc9d-1af71781b333.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a8a9ab8a-359c-4d7d-aee7-8f57042f5f60.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5ca5b63f-722e-4177-a552-63bf4e739862.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b4286a45-7750-4446-83a8-c41c0e669e66.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f1757d6a-a780-40ce-8875-b1d01d99326b.jpg: 640x480 1 face, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cf8b77d8-17f1-4f72-a7a8-d5807a51e27f.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d9df2af7-7891-4fce-a032-73004fb2716d.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7efbf3ef-4bbb-415a-96b1-363630b31acc.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ca019006-b599-42d1-b7d9-724a8db66695.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e0c78590-191b-4704-af0b-aa237a45691a.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fa3f45bc-96de-489d-88b5-4c863dafd994.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02ce1b4a-bb44-4084-8c89-28d1d0dd5869.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/130e375c-c4e8-4ece-bb44-3694f9ad0892.jpg: 640x480 1 face, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/77827c30-fe44-4d34-929c-ec7f9b5dff2e.jpg: 640x384 1 face, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f89a4212-242d-43ff-b10e-158f1ab471a0.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/565b953f-a581-4631-9de0-a884064e5ac2.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a215a729-ddcf-45b5-9d00-e20c0b888af1.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ca9c918d-843b-490d-88df-98beb5db8b06.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eed03856-8e6e-4609-9c16-7944109b6310.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8543ca3b-dfa1-4ea8-bda8-a17a7306a4fe.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0348346a-52a4-4851-bd7e-89ac7528c8f7.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e8ff8301-c391-4516-8cff-2e4aed10b73a.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa664306-5636-4a18-b308-1113147e04d8.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/19028812-bd5c-4feb-bb74-2e8a06b7ffff.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e507d21c-b215-4baf-aff0-1bbf50df7e12.jpg: 640x384 1 face, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e65bf694-bcda-4521-be3f-47b9e0382479.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b40edde5-ed55-468c-a920-42386e1278bb.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/05b12d2f-72f9-4f82-b99c-83a63f700955.jpg: 640x384 2 faces, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fdf535e1-b85a-4a2b-942a-899f77afd499.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c91292b3-2528-4f7e-af83-8bb7428cc2b2.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4e9a3bc1-5905-45df-9b3c-6f00d921110f.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/58d917ff-5617-4c4f-8c2e-ba0aaa93710e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/714c9365-ff2e-41a5-ba74-9c5685db20ad.jpg: 640x416 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a53b28f5-f0b5-4975-811b-00ef72f1af84.jpg: 640x384 1 face, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2d610a2e-3dc0-45a6-b061-7e1d0e14ef9a.jpg: 640x416 1 face, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e626cf76-ae91-4c85-b2ee-f0aa864a1ed0.jpg: 640x384 1 face, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/07c1e92d-2acb-45a3-a4be-e6d97a62015b.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/acdb2a01-d3b4-4b03-b0ec-db381026904e.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9aea2375-c8af-4781-898d-368dcd06086b.jpg: 640x416 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8c4d1bef-0ab5-4137-b9af-37824f425e8b.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.8ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9bda8c90-79b4-4f56-afa1-01a4da35a231.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f5ed19b7-3ee2-475f-9a9a-95cb0877632e.jpg: 640x416 1 face, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b3425b70-4fe8-472b-b2eb-dde4af3a9570.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2109fc5c-6309-48c1-8257-182ac1c9b609.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4feaa34f-0a0e-462e-a355-498b2f404608.jpg: 640x384 1 face, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7e978cfd-5b82-44c6-8128-a0bed2e94482.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1002033d-6596-493e-a328-dbe7863f5305.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/be0e33e4-bcdb-4400-aab1-71209ef764c2.jpg: 640x384 1 face, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/07624b93-6ad3-459c-a805-12539873c1a5.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e1efa915-2c3a-4748-989c-db3d9c79e400.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9bb545ba-00ba-4715-ba17-005f8238283e.jpg: 640x384 1 face, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7c3c82e1-2244-4bc4-8861-64b734e903b6.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/51a091f6-453f-4910-bdb2-bdac82103cb9.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0dff9c08-0aa4-4158-9b74-42dec68d2905.jpg: 640x480 1 face, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4064316f-714b-4030-a27d-6eeaf794fe4d.jpg: 640x416 1 face, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5d916695-f3b6-4aa0-a851-0398fbb62c36.jpg: 640x384 1 face, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/768a94e3-059e-4e42-80c1-9708f021874f.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/081466e0-b3ed-495e-b6aa-b173f69acb5e.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/38dc1524-8844-4377-b16e-980a7d4a68f6.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7e0886dd-83ea-4a90-b3b3-30cf6d816689.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/330fcb07-9505-40a9-a2e9-c455d326f734.jpg: 640x384 1 face, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e231675c-0e23-4501-b043-8f2e195f4513.jpg: 640x384 1 face, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b9be5c05-9323-48d8-916d-d135afd63c98.jpg: 640x384 1 face, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d6ed50a1-90d8-4e38-b49c-049c565066ac.jpg: 640x384 1 face, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ae4076bd-3e58-480e-84ce-717ee8790a59.jpg: 640x384 1 face, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f682432c-d073-4768-8a20-250722cfd8b2.jpg: 640x384 1 face, 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2b36c043-ed48-4ff1-b047-b3fc866af09a.jpg: 640x384 1 face, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cd8b9666-604f-4198-8e3c-b4cee2a3fe93.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/24a2a994-d21b-4afd-8e21-adafba4e7211.jpg: 640x384 1 face, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/35574787-200b-40be-a34c-e69ba1be39b2.jpg: 640x384 1 face, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First inference: 111.7ms\n",
      "Total time: 8377.18ms\n",
      "Image count: 913 images\n",
      "Average predict time (excluding first warmup): 9.18ms\n",
      "Total image count (including first warmup): 914 images\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "item_count = 0\n",
    "total_count = 0\n",
    "flag = True\n",
    "\n",
    "\n",
    "weight = \"/home/intern/jingjie/Projects/DevYOLOv8Face/runs/pose/Train1_wiseai_100epochs_defArgs/weights/yolov8n-pose.pt\"\n",
    "model = YOLO(weight) \n",
    "\n",
    "image_dir = '/mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images'\n",
    "for filename in os.listdir(image_dir): \n",
    "    file_path = os.path.join(image_dir, filename)\n",
    "    results = model(file_path)\n",
    "    total_speed = round(results[0].speed['preprocess'] + results[0].speed['inference']+ results[0].speed['postprocess'],2)\n",
    "    total_count += 1 \n",
    "    if flag == True:\n",
    "        flag = False\n",
    "        first_inference = total_speed\n",
    "    else:\n",
    "        total_time += total_speed\n",
    "        item_count += 1\n",
    "\n",
    "print(f\"First inference: {first_inference}ms\")\n",
    "print(f'Total time: {round(total_time,2)}ms')\n",
    "print(f'Image count: {item_count} images')\n",
    "print(f'Average predict time (excluding first warmup): {round(total_time/item_count,2)}ms')\n",
    "print(f'Total image count (including first warmup): {total_count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
