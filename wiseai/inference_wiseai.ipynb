{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b35d0791-0bb1-479f-8cc3-013852ce8697.jpg: 640x384 1 person, 105.8ms\n",
      "Speed: 1.6ms preprocess, 105.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed85e3a7-acc9-49d5-95fa-47adf44f87b2.jpg: 640x384 2 persons, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e72fff25-b22e-4eb9-b3dd-3ad701a89d4d.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7464335d-9d30-46fc-9493-f62cad6c4c06.jpg: 640x480 2 persons, 106.2ms\n",
      "Speed: 2.0ms preprocess, 106.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6fafe175-4dd6-44a2-8aad-6be2f86accd2.jpg: 640x480 1 person, 5.4ms\n",
      "Speed: 1.6ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8d2490ab-63c2-4863-9640-d02ee4bfcc5b.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.6ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aaede6bd-db7a-4ca4-a014-ecc08abc4692.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bf0ff114-3191-4dc9-a68d-8d5765f0c0aa.jpg: 640x384 1 person, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/21063659-c586-46bd-928c-9ffd05d0c72d.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f0b8a925-3552-4920-a562-6d77913184df.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fe35770-d1d1-4542-b9be-c0df22dbdf84.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1196aa77-79be-4d03-8b4a-5a69596784be.jpg: 640x416 1 person, 109.6ms\n",
      "Speed: 1.6ms preprocess, 109.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/eeedf8b4-5184-4cdc-9e94-c7a8153471ac.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b2779c0a-1c11-439f-a1a9-c4a5b6c2894b.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/90438969-d462-4a31-b2f6-26b5f21afe3a.jpg: 640x384 4 persons, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb1016cf-af6b-44f9-8832-e9f0e089998d.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f94b020f-9a55-46aa-93ec-b5a9319cdb7d.jpg: 640x384 2 persons, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/227c2acd-b9ef-4479-9e82-c65fb4bc832e.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4856f564-df61-4711-9649-22438d137add.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2de2bc1b-dd43-4d9d-8963-a793b75fb556.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ffd68b82-520e-4197-992a-d542841463dd.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6268e735-46d4-4561-9377-c3890395ab4b.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b16a476-4f86-49de-a855-66b88258f4d8.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5253820f-5b87-4110-a97d-6999c8db5957.jpg: 640x480 1 person, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/02301118-baa1-4f4a-8708-2d2dc8326493.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d7921dff-c4a8-4f2f-8b28-e46a12ae6d37.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9c42ce5b-a8ae-4ef1-bc67-222be6861763.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb7f866e-7991-462d-b952-0814b0e61289.jpg: 640x416 1 person, 6.0ms\n",
      "Speed: 1.5ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0cb68101-8330-4748-b9ee-c87543ea3fce.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2832a3f6-f57b-4639-827f-ad179f4b35da.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e3ea4651-064e-4c1b-ac92-b4d9e3700006.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/08146453-b859-4f9f-b541-5d419be69b3c.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0f127a7a-ae96-447b-8645-3b5511500c62.jpg: 640x384 1 person, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/65e54017-150c-439a-9cdb-b23e19cd5963.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/094c272e-d3b6-4535-b82d-c11b9f13b03f.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2f1c72fb-7519-4ecb-9e3b-d4d67efe57e4.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9d54d3dd-1440-4ff1-a60d-659ee12a3d7c.jpg: 640x384 2 persons, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/71091bec-2e4a-4834-8475-70a6a9ad1bff.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8407e0de-0323-4442-bb15-bb2cb1bfdda4.jpg: 640x384 1 person, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5cbb7d55-40f8-4967-9b59-8909abc7818e.jpg: 640x416 1 person, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5c3f292a-f526-44e6-94de-1635a85cc7a0.jpg: 640x384 2 persons, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fcd62e4b-93ca-4fa7-a0c8-c1c2d9b60028.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0e2e6322-962b-4c2a-9c9e-142eeac32d27.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4fcfb9d7-cb5f-44ec-a311-a583673aa93c.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/60186f9c-07fb-4426-8713-78a411158539.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed39b2c7-a636-4f7a-96e0-62bd55e835b2.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6cd2d740-9501-44be-829f-dd3f8c15d050.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/72a68e4a-abe2-4c23-a729-ad36fa3e31ab.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7604e119-f192-43ae-9847-4bc795fc4a15.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ebd1fa5a-2296-42b5-9d87-0a2f0515473d.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/29ad0a72-a2a4-46ff-ad80-45db8be07168.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8e8ba00c-3d8e-4ecd-8fde-8c394b3ead8d.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a54d67e2-6cc4-4933-b24a-b31d506f4877.jpg: 640x384 3 persons, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/87773848-eda7-49a3-838a-716cb7381c14.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9507a7e6-d2cd-4a13-b4c8-a72292f4e587.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8186d58f-ec21-4284-9678-60a3ffd6f75a.jpg: 640x384 2 persons, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f7df26dd-bd76-4a6a-a4fc-4e1f2c5918ef.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0197273a-ffc6-4ef4-8e7a-a484449a152b.jpg: 640x384 3 persons, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e20bc885-e123-4f88-bcdb-21037e65c931.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e914ab54-5e78-4845-a3f4-80b6189b115e.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/25c5a9ca-45c3-4b38-80e9-fbd905be1392.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc2ee022-9249-4089-a81a-651f5b0a7426.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4244c0de-1cae-4d8c-8cd2-ba69938d3a2b.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f430e7e-005a-40ac-b0a8-611f6c4fb445.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/06cae16e-f18a-4963-b293-8f66510bab3d.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8509d490-8a18-4e8b-956a-70073ad59163.jpg: 640x384 1 person, 7.6ms\n",
      "Speed: 2.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/208158c3-d2ec-4791-b426-893f1ffdd555.jpg: 640x384 2 persons, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b63ab055-4a97-40ef-9352-8affe5566626.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.6ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8ffd6bd7-1745-4c33-ae47-9e030fe4a565.jpg: 640x384 1 person, 6.0ms\n",
      "Speed: 1.7ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d444e19-de62-4ed3-a1c8-c168f4ca250a.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f00e4de1-5781-4488-a069-509fd7bc2306.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/94bb2cb0-1d4d-4207-a4f9-0a619ee27c51.jpg: 640x384 1 person, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e0907964-0b04-4c1e-820f-a25b479f67fb.jpg: 640x480 4 persons, 6.2ms\n",
      "Speed: 2.1ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/42e67695-ca98-4e0c-8690-ec6d56c346fd.jpg: 640x384 1 person, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2b145af7-c8e1-4d3d-8a2b-b6f2b58d8059.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/57cd2625-f532-47ae-b15f-496dc4162bdf.jpg: 640x384 2 persons, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/83ea52cf-f8ad-4ad2-a116-5e3c3cf107f2.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/340dd0b6-8bc4-4729-954b-f09669ec6b84.jpg: 640x384 1 person, 11.0ms\n",
      "Speed: 3.7ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f8104655-49c6-489e-96b9-b9392eebaaeb.jpg: 640x384 1 person, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b1d2a729-79bb-49a1-9a93-151b79151d3a.jpg: 640x384 2 persons, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fc9a4504-1ef9-4b82-903e-428f3db3c967.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fe7e6e34-fa14-4908-b95d-3ef62945538f.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/62f35e8a-4348-40d9-a13c-6720c6a620ff.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/92af2d20-5871-4fee-b73f-d5acc99f362d.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3e24bd54-c64b-4110-923b-8b378a0b9c93.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0489e41f-4568-461b-888e-a40e4553191b.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5670916f-7101-4972-9e94-3d6f383f6c90.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/586e44b2-330b-4794-9338-75923e18227b.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b6a1d986-4a0c-4c78-bd4d-5152bdb4cd40.jpg: 640x384 3 persons, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/64a8bf2d-3fba-4409-8a38-0cc4bc1eb6ed.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5791a874-a020-426e-b011-2f66b083872b.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/62c47520-2ad7-4c01-b260-cc8d810c13b3.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f7db7f28-8591-44ea-8f97-4a992a67c831.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e341d476-f11a-4f45-8569-c4dc1eea25b3.jpg: 640x384 3 persons, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cd46ba0e-c901-472b-b44e-552c650ddaad.jpg: 640x480 1 person, 5.6ms\n",
      "Speed: 1.7ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bdbc0311-448b-4ad4-8ab5-b6aa9714149e.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d63a86e6-2c2f-429e-81b7-be0f7725f698.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2db25e2c-b437-41ca-a2cd-0e4f60ec6171.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1ac488b7-51eb-4a59-ad84-cd2da0de9c50.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/127f4466-d095-405c-941b-2491d192a810.jpg: 640x416 1 person, 6.2ms\n",
      "Speed: 1.6ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a9c16d79-d7bf-4edf-bd3c-744bed19e192.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/80aade55-7a13-4fb4-b63e-cc61a721c0f5.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e53fa46a-ff2d-4b1f-9729-1d589a84573f.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3d8dd307-5a03-4146-b6b0-720946fb799e.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2afc9b75-97fe-4010-ac17-4a807a6a3904.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5ede2524-9850-42ad-9fdf-bb4f944cda0a.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.6ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b9cda16-afb9-4a31-b43b-87895ce4b948.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e444a994-d58c-41dc-94c8-b5bf0a68bb13.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/59567b40-a09b-4c39-ad1d-5c2223e12adc.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3deb33f6-9a3b-4b10-a73f-aa56dd1e72fa.jpg: 640x384 2 persons, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e871fc04-56b9-45ac-a13e-96a053f40b1c.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.3ms preprocess, 5.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/929402a1-095f-4bd9-a4d8-bc9773beb226.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3a72c885-47b4-4bca-ace8-7807cf00fe48.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2acb7ceb-ec49-4380-b9b7-0d2fbf77f783.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ed419063-a499-4992-8c76-4e13e31ffd0d.jpg: 640x480 1 person, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dd39b876-385e-4267-b46a-f2a72f2585c0.jpg: 640x384 1 person, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/292fffac-cabf-4bfc-bbde-73f08df4e9d6.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/98cfebfc-5ebd-4272-af6f-eba193e55193.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/73cfe5e3-8819-417a-81b9-4a9650fba472.jpg: 640x384 1 person, 11.1ms\n",
      "Speed: 3.7ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c0e04bc8-1ee9-4589-933e-e53a384868ab.jpg: 640x384 1 person, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/52dc9454-ee3e-4eb2-8d55-c4e96a41d76f.jpg: 640x384 1 person, 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/57fc0fe2-8c55-4d68-9714-f6a6b5a9c94b.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fa7268ce-be04-4af0-b5b8-7ad5cc13aa24.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/301cd3c0-1fd9-47a9-aa54-d4d763e08e82.jpg: 640x384 1 person, 9.9ms\n",
      "Speed: 2.8ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1ff52429-ac72-411a-b7c7-13a5a7709088.jpg: 640x384 1 person, 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/661e32b0-9c45-4e40-bab0-10f46c960a05.jpg: 640x384 1 person, 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/db0d4701-ba6a-4d61-a7ba-283adb6ab22c.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1432516f-4cb7-4d42-9d8a-295165144c63.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.3ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9addd114-8a17-473b-994f-7f7c0e5fee28.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ad5b2db7-0816-4591-ba8a-046a4b1e534e.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/64225b16-0bf0-4487-aeb6-371c0628b797.jpg: 640x480 1 person, 8.7ms\n",
      "Speed: 2.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e348d7f8-b89e-4d1c-a207-5b0234485ead.jpg: 640x384 1 person, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8c07266b-fe34-4300-8cc9-a53ca2e48145.jpg: 640x384 1 person, 14.3ms\n",
      "Speed: 3.7ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b9db7fb-2751-4409-9112-fe67ff5a7386.jpg: 640x480 6 persons, 8.9ms\n",
      "Speed: 2.4ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5e116d74-da91-4fd0-945d-c1dc74fde359.jpg: 640x384 1 person, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cb172f25-691f-4d65-ad2f-fdb4ae259c33.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d755d32b-7097-4e5b-b23e-3e5c3fc98c83.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6d61bd53-dee1-4927-b3ba-93d18fa15e2a.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/11f88196-6992-4512-80f6-7adb3ab73291.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/27b8a0d6-f8a2-422d-b86d-352004ae1386.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4385b08-2432-4e31-b68b-6623055a2dd4.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ca5a772a-402c-43f4-ad45-85862ec58cd5.jpg: 640x384 1 person, 12.5ms\n",
      "Speed: 5.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/169080da-7143-4e23-b80b-c2d8062fd885.jpg: 640x384 1 person, 6.1ms\n",
      "Speed: 1.7ms preprocess, 6.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/339dac7c-96a5-4669-bb95-f15980996915.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c7ad57f6-6569-4dba-9709-5e1c5acb10e7.jpg: 640x384 2 persons, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/58c156b2-e068-4ba3-a75d-3431f007ea44.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d778d0a6-79e5-409c-bdd0-9f209b20a465.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0fb6f45f-5d46-4659-a001-b9695972b2eb.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ff24ee66-ddf7-4597-a8c1-70900aec0e94.jpg: 640x384 2 persons, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/097c1aef-cb9c-4908-a452-ea6f67ef2f9a.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e5bbe438-0c0a-4477-9ea2-d93ff9230ebb.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81ff11d8-9cca-40c3-b901-0e635ae3535e.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd8e7198-7a3d-4dc1-9edb-c2af543bf7f9.jpg: 384x640 1 person, 102.9ms\n",
      "Speed: 1.7ms preprocess, 102.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/7006f08c-db51-4f85-98cf-1eeeba9de217.jpg: 640x384 1 person, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e6add8f3-bbc9-4c49-aa50-4e11edf47118.jpg: 640x384 2 persons, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9b99bf75-92e6-4d42-b637-0e398f456ae3.jpg: 640x480 1 person, 5.7ms\n",
      "Speed: 1.7ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/97d7c632-3035-41f2-919c-858fbc7be4bf.jpg: 640x480 1 person, 5.5ms\n",
      "Speed: 1.7ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6d614945-96c9-4b9a-9002-848f30078daf.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/99bf3278-f9fa-4305-b63c-14d3d03b0041.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aa661d81-7b0c-491d-ab57-e2a761b6df12.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/aec77992-f2c8-4db0-99ba-cc5df90e20a2.jpg: 640x384 2 persons, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/111da176-4272-4c8c-89f7-e5c9edcedafb.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/252889d4-6534-4925-b674-4d7549042c90.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/63b94c54-da68-48b7-b26f-008698cf20e7.jpg: 640x416 1 person, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1d1fb904-428e-405e-a105-99c21a9c055a.jpg: 640x384 1 person, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3561b0aa-c4f9-4cf7-a0b8-d1c09cff37b9.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/e7ae8f4b-2705-4434-b902-862b6a4a0afc.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1dbfd7ad-8450-47fc-87d2-ffe112bb70ad.jpg: 640x384 2 persons, 5.8ms\n",
      "Speed: 1.5ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4417f226-63b7-4a1d-bdc0-3b3a71143dd6.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ddf9088c-2719-42f8-b16b-806ef3039561.jpg: 640x384 1 person, 6.1ms\n",
      "Speed: 1.5ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/570fafee-fac9-4106-935e-928bb2768dc8.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f4d481c8-55ee-4f58-9388-37b940b3665c.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/46bf17f6-0064-4de0-9d04-75a6c517ed05.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4b1f3549-7a16-4699-8391-bf79c2e3577a.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ee380fac-d0f5-45ac-8de7-579d9259c7ec.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/b3398513-f49a-4570-9a0e-bf5f2849eb6a.jpg: 640x384 2 persons, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1faa9796-0875-4925-bd27-341e50ca61a4.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d103afdb-fb68-41d3-b1d4-9d7a0f6da68c.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d316cb19-edf3-4467-a2f3-650e11c0f86f.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/3f674758-b142-4d0b-a32a-0de4c0a90198.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/96f8bc01-d17d-41b5-9191-f231688d9d0b.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5f4556aa-5cad-4e89-b5b8-6351723d6858.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/c5c165c7-e016-4176-a101-287a98cc9167.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/dbc5967e-0dd1-4298-9a36-39c7654cdec9.jpg: 640x384 3 persons, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/0b2820b1-7227-436d-a406-8562e5d54dd6.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8a19ea4e-4385-4103-93d0-aa5f8f2c86e1.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/1cb7cd68-0cf2-4f7c-8b1c-406f2a308b45.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/81e0990e-63d0-4482-8b87-1dee16dade99.jpg: 640x384 2 persons, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bd063a6e-ac38-42ed-963a-8b280e8d9b1d.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/63c7b9c3-ef17-413a-a4d0-abf3eb2ebdd6.jpg: 640x384 1 person, 5.8ms\n",
      "Speed: 1.4ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f77a3d93-9bb7-4f1e-a93d-1012bc57d234.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fbc89050-bbc3-4150-81b6-0f74fdb21e6e.jpg: 640x384 2 persons, 6.1ms\n",
      "Speed: 1.3ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/2478a5c2-262f-48d3-b847-3e996450be4a.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/069725a5-6099-4978-b0c4-c28553e865f4.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/fca34be3-74fa-4350-8278-9a4ef1346fe8.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/9d9e23d4-dcf2-4800-aaaf-327648022937.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/10e9f366-9723-4eb0-bb85-b463f2a96b76.jpg: 640x384 1 person, 5.7ms\n",
      "Speed: 1.4ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/bb752330-2d85-4e88-b9c0-81a2553b7d86.jpg: 640x480 1 person, 6.2ms\n",
      "Speed: 1.8ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/53bf810c-96fd-4fad-9d7d-98234cdd5a75.jpg: 640x384 2 persons, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/532a7504-5143-402c-8074-ca7da804f751.jpg: 640x384 2 persons, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/ec4e0d17-e8c6-489f-b57d-89ab61457dd1.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a35f3b04-5142-40a6-8f49-83196cb0fce5.jpg: 640x384 2 persons, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/74f03f7b-57cf-488e-850d-f51c41402c40.jpg: 640x384 1 person, 11.4ms\n",
      "Speed: 3.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f46f6e5c-bf72-4d9b-ae81-789053ef179b.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/44ae5cdc-c914-41b1-bf0a-2aa24262743c.jpg: 640x480 1 person, 5.8ms\n",
      "Speed: 1.7ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/4433d0d8-df0d-4d87-b950-a8b49252b593.jpg: 640x384 1 person, 6.1ms\n",
      "Speed: 1.4ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d7b48e7b-82a2-4b38-85e2-1eec35958669.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/a53b36c4-82dc-4565-a119-5c6474a56970.jpg: 640x384 1 person, 5.3ms\n",
      "Speed: 1.5ms preprocess, 5.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/6e5d21e9-3759-4f44-9e8d-7c504d0673d7.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/cce482b4-8851-4b33-80ad-da9a718f4da0.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/78adaca9-9a20-44e0-a365-3c3a888123a5.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/204f8f2d-c4b8-4b1a-89e7-030e0026ad20.jpg: 640x384 1 person, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/83f7a76a-eacd-4052-a325-62e5870eecb0.jpg: 640x384 1 person, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/5fa55c00-3a01-450d-bc6f-3caa29a80500.jpg: 640x384 1 person, 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/211ce129-5d66-4dd3-9a6e-3eba82a8ea3b.jpg: 640x384 2 persons, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/f744f0de-6717-442c-8212-c41909e9bbea.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.4ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/8032ce52-4e81-4382-b77f-044b6b536b4e.jpg: 640x384 1 person, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images/d1e7c045-5a5f-4313-8c25-4f037d816b86.jpg: 640x384 1 person, 5.5ms\n",
      "Speed: 1.5ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "item_count = 0\n",
    "total_count = 0\n",
    "flag = True\n",
    "\n",
    "\n",
    "weight = \"/home/intern/jingjie/Projects/DevYOLOv8Face/runs/pose/Train1_wiseai_100epochs_defArgs/weights/yolov8n-pose.pt\"\n",
    "model = YOLO(weight) \n",
    "\n",
    "image_dir = '/mnt2/shared/jingjie/YOLOv8Face_wiseai/val/images'\n",
    "for filename in os.listdir(image_dir): \n",
    "    file_path = os.path.join(image_dir, filename)\n",
    "    results = model(file_path)\n",
    "    total_speed = round(results[0].speed['preprocess'] + results[0].speed['inference']+ results[0].speed['postprocess'],2)\n",
    "    total_count += 1 \n",
    "    if flag == True:\n",
    "        flag = False\n",
    "        first_inference = total_speed\n",
    "    else:\n",
    "        total_time += total_speed\n",
    "        item_count += 1\n",
    "\n",
    "print(f\"First inference: {first_inference}ms\")\n",
    "print(f'Total time: {round(total_time,2)}ms')\n",
    "print(f'Image count: {item_count} images')\n",
    "print(f'Average predict time (excluding first warmup): {round(total_time/item_count,2)}ms')\n",
    "print(f'Total image count (including first warmup): {total_count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
